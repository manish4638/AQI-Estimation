{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e7cac6-039e-4547-8a40-277f028dccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from functools import lru_cache\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline  # For inline plotting in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321ea812-eee0-418c-8cca-bdd921ecbb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Loading with Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed860e4-f69f-456f-8299-4b0c9fc7aff6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_data_list\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m image_data_list \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_with_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(image_data_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m, in \u001b[0;36mload_images_with_data\u001b[1;34m(image_dir, csv_file)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(image_path):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m         img_resized \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m         values \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m     25\u001b[0m         values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m img_resized\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mload_and_preprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_and_preprocess_image\u001b[39m(image_path):\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load and preprocess an image, cached by file path.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load image at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iMAGE_PIXEL = 100\n",
    "BATCH_SIZE = 16\n",
    "@lru_cache(maxsize=1000)\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess an image, cached by file path.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image at {image_path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return cv2.resize(img, (iMAGE_PIXEL, iMAGE_PIXEL))\n",
    "\n",
    "def load_images_with_data(image_dir=\"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_folder\",\n",
    "                         csv_file=\"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_data.csv\"):\n",
    "    \"\"\"Load images and data with caching.\"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    image_data_list = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        image_name = row['Filename']\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        if os.path.exists(image_path):\n",
    "            try:\n",
    "                img_resized = load_and_preprocess_image(image_path)\n",
    "                values = row.to_dict()\n",
    "                values['image'] = img_resized\n",
    "                image_data_list.append(values)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Image '{image_name}' not found in '{image_dir}'.\")\n",
    "    return image_data_list\n",
    "\n",
    "# Load data\n",
    "image_data_list = load_images_with_data()\n",
    "print(f\"Loaded {len(image_data_list)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401cec89-c3dd-41e1-8741-50c10edd1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iMAGE_PIXEL = 100\n",
    "BATCH_SIZE = 16\n",
    "@lru_cache(maxsize=1000)\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess an image, cached by file path.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image at {image_path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return cv2.resize(img, (iMAGE_PIXEL, iMAGE_PIXEL))\n",
    "\n",
    "def load_images_with_data(image_dir=\"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_folder\",\n",
    "                         csv_file=\"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_data.csv\"):\n",
    "    \"\"\"Load images and data with caching.\"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    image_data_list = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        image_name = row['Filename']\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        if os.path.exists(image_path):\n",
    "            try:\n",
    "                img_resized = load_and_preprocess_image(image_path)\n",
    "                values = row.to_dict()\n",
    "                values['image'] = img_resized\n",
    "                image_data_list.append(values)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Image '{image_name}' not found in '{image_dir}'.\")\n",
    "    return image_data_list\n",
    "\n",
    "# Load data\n",
    "image_data_list = load_images_with_data()\n",
    "print(f\"Loaded {len(image_data_list)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2dfdfb-4658-49c1-8160-7fe35757dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iMAGE_PIXEL = 100\n",
    "BATCH_SIZE = 16\n",
    "@lru_cache(maxsize=1000)\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess an image, cached by file path.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image at {image_path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return cv2.resize(img, (iMAGE_PIXEL, iMAGE_PIXEL))\n",
    "\n",
    "def load_images_with_data(image_dir=\"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_folder\",\n",
    "                         csv_file=\"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_data.csv\"):\n",
    "    \"\"\"Load images and data with caching.\"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    image_data_list = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        image_name = row['Filename']\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        if os.path.exists(image_path):\n",
    "            try:\n",
    "                img_resized = load_and_preprocess_image(image_path)\n",
    "                values = row.to_dict()\n",
    "                values['image'] = img_resized\n",
    "                image_data_list.append(values)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Image '{image_name}' not found in '{image_dir}'.\")\n",
    "    return image_data_list\n",
    "\n",
    "# Load data\n",
    "image_data_list = load_images_with_data()\n",
    "print(f\"Loaded {len(image_data_list)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f2fd7-12cb-413e-a0eb-87b83887fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1000)\n",
    "def segment_sky(image_tuple):\n",
    "    \"\"\"Segment sky from image, cached by image content.\"\"\"\n",
    "    # Reshape the flattened tuple back to (224, 224, 3)\n",
    "    image = np.array(image_tuple, dtype=np.uint8).reshape(iMAGE_PIXEL, iMAGE_PIXEL, 3)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    lower_blue = np.array([90, 50, 50])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "def prepare_dataset(image_data_list):\n",
    "    \"\"\"Prepare dataset with caching.\"\"\"\n",
    "    X = []\n",
    "    y_dict = {'AQI': [], 'PM2.5': [], 'PM10': [], 'O3': [], 'CO': [], 'SO2': [], 'NO2': []}\n",
    "    \n",
    "    for data in image_data_list:\n",
    "        # Convert 3D image array to tuple for caching\n",
    "        img_tuple = tuple(data['image'].ravel())  # ravel() is equivalent to flatten()\n",
    "        sky_img = segment_sky(img_tuple)\n",
    "        sky_img = preprocess_input(sky_img)\n",
    "        X.append(sky_img)\n",
    "        for param in y_dict.keys():\n",
    "            y_dict[param].append(data[param])\n",
    "    \n",
    "    return np.array(X), {k: np.array(v) for k, v in y_dict.items()}\n",
    "\n",
    "# Prepare dataset\n",
    "X, y_dict = prepare_dataset(image_data_list)\n",
    "print(f\"Dataset shape: X={X.shape}, y_dict keys={list(y_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337f432-081a-4b75-8659-3e41abda1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape=(iMAGE_PIXEL, iMAGE_PIXEL, 3)):\n",
    "    \"\"\"Build the CNN model.\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Example model summary\n",
    "model = build_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7aea1-5acd-4ddd-86c1-96b3cf08c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X, y_dict):\n",
    "    \"\"\"Train models for each parameter and report data counts.\"\"\"\n",
    "    models = {}\n",
    "    histories = {}\n",
    "    \n",
    "    for param, y_values in y_dict.items():\n",
    "        print(f\"\\nTraining model for {param}\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_values, test_size=0.2, random_state=42)\n",
    "        print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")  # Data counts\n",
    "        print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "        model = build_cnn_model()\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                           epochs=20, batch_size=BATCH_SIZE, verbose=1)\n",
    "        models[param] = model\n",
    "        histories[param] = history\n",
    "    return models, histories\n",
    "\n",
    "# Train models\n",
    "models, histories = train_models(X, y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af3f19-e089-41a8-a7ba-b3f7f67ae510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MAE for each parameter\n",
    "plt.figure(figsize=(12, 6))\n",
    "for param, history in histories.items():\n",
    "    plt.plot(history.history['mae'], label=f'{param} Train MAE')\n",
    "    plt.plot(history.history['val_mae'], label=f'{param} Val MAE', linestyle='--')\n",
    "plt.title('Training and Validation MAE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff10b6b-e5bd-44b9-858c-3fe2fc1937ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(models, X_test=None, y_test_dict=None, new_image_path=None):\n",
    "    \"\"\"Test models with MSE, MAE, R², and data counts.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    if X_test is not None and y_test_dict is not None:\n",
    "        print(f\"\\nEvaluating on test data (samples: {X_test.shape[0]})\")\n",
    "        for param, model in models.items():\n",
    "            test_loss, test_mae = model.evaluate(X_test, y_test_dict[param], verbose=0)\n",
    "            y_pred = model.predict(X_test, verbose=0).flatten()  # Predictions for R²\n",
    "            r2 = r2_score(y_test_dict[param], y_pred)  # Calculate R² score\n",
    "            results[param] = {'MSE': test_loss, 'MAE': test_mae, 'R²': r2}\n",
    "            print(f\"{param} - Test MSE: {test_loss:.4f}, Test MAE: {test_mae:.4f}, R²: {r2:.4f}\")\n",
    "    \n",
    "    elif new_image_path is not None:\n",
    "        print(\"\\nPredicting for a new image:\")\n",
    "        img_resized = load_and_preprocess_image(new_image_path)\n",
    "        img_tuple = tuple(img_resized.ravel())\n",
    "        sky_img = segment_sky(img_tuple)\n",
    "        sky_img = preprocess_input(sky_img)\n",
    "        sky_img = np.expand_dims(sky_img, axis=0)\n",
    "        \n",
    "        for param, model in models.items():\n",
    "            pred = model.predict(sky_img, verbose=0)[0][0]\n",
    "            results[param] = pred\n",
    "            print(f\"Predicted {param}: {pred:.4f}\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Provide either test data or new_image_path\")\n",
    "    return results\n",
    "\n",
    "# Split data for testing\n",
    "X_train, X_test, y_train_dict, y_test_dict = {}, {}, {}, {}\n",
    "for param, y_values in y_dict.items():\n",
    "    X_train[param], X_test[param], y_train_dict[param], y_test_dict[param] = train_test_split(\n",
    "        X, y_values, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "# Evaluate on test data\n",
    "test_results = test_model(models, X_test['AQI'], y_test_dict)\n",
    "\n",
    "# Predict for a new image\n",
    "new_image = \"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_folder/BRI_Un_2023-02-02- 12.00-9.jpg\"\n",
    "pred_results = test_model(models, new_image_path=new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f949003-2254-42c6-995f-059cc24580a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the new image and its predictions\n",
    "img = load_and_preprocess_image(new_image)\n",
    "sky_img = segment_sky(tuple(img.flatten()))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(sky_img)\n",
    "plt.title(\"Segmented Sky\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"Sample Image with Predictions:\\n\" + \n",
    "             \"\\n\".join(f\"{param}: {value:.2f}\" for param, value in pred_results.items()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109efd7-00b5-4d20-82b1-e4ccf7414b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521ede7-0dc0-4016-b660-648869ca61ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
