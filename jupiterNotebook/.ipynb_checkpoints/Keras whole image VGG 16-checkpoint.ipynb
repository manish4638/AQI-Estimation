{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b64bd17-ce5a-4e31-ac12-3fa042825940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10610 images\n",
      "Dataset shape: X=(10610, 32, 32, 3), y_dict keys=['AQI', 'PM2.5', 'PM10', 'O3', 'CO', 'SO2', 'NO2']\n",
      "\n",
      "Training model for AQI\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'callbacks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m models, histories\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Train models\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m models, histories \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Cell 6: Plot MAE for each parameter\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param, history \u001b[38;5;129;01min\u001b[39;00m histories\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[1], line 108\u001b[0m, in \u001b[0;36mtrain_models\u001b[1;34m(X, y_dict)\u001b[0m\n\u001b[0;32m     99\u001b[0m  model \u001b[38;5;241m=\u001b[39m build_transfer_model()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# callbacks = [\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m#     EarlyStopping(patience=5, restore_best_weights=True),\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#     ModelCheckpoint(f\"best_model_{param}.h5\", save_best_only=True)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[0;32m    106\u001b[0m  history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[0;32m    107\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m--> 108\u001b[0m                      callbacks\u001b[38;5;241m=\u001b[39m\u001b[43mcallbacks\u001b[49m)\n\u001b[0;32m    109\u001b[0m  models[param] \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    110\u001b[0m  histories[param] \u001b[38;5;241m=\u001b[39m history\n",
      "\u001b[1;31mNameError\u001b[0m: name 'callbacks' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and constants\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from functools import lru_cache\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iMAGE_PIXEL = 32\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Cell 2: Image loading functions\n",
    "@lru_cache(maxsize=100000)\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image at {image_path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return cv2.resize(img, (iMAGE_PIXEL, iMAGE_PIXEL))\n",
    "\n",
    "def load_images_with_data(image_dir, csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    image_data_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        image_name = row['Filename']\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        if os.path.exists(image_path):\n",
    "            try:\n",
    "                img_resized = load_and_preprocess_image(image_path)\n",
    "                values = row.to_dict()\n",
    "                values['image'] = img_resized\n",
    "                image_data_list.append(values)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Image '{image_name}' not found in '{image_dir}'.\")\n",
    "    return image_data_list\n",
    "\n",
    "# Load data\n",
    "image_dir = \"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_folder\"\n",
    "csv_file = \"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_data.csv\"\n",
    "image_data_list = load_images_with_data(image_dir, csv_file)\n",
    "print(f\"Loaded {len(image_data_list)} images\")\n",
    "\n",
    "# Cell 3: Dataset preparation with normalization\n",
    "def prepare_dataset(image_data_list):\n",
    "    X = []\n",
    "    y_dict = {'AQI': [], 'PM2.5': [], 'PM10': [], 'O3': [], 'CO': [], 'SO2': [], 'NO2': []}\n",
    "    for data in image_data_list:\n",
    "        img = preprocess_input(data['image'])\n",
    "        X.append(img)\n",
    "        for param in y_dict:\n",
    "            y_dict[param].append(data[param])\n",
    "    X = np.array(X)\n",
    "    \n",
    "    scaler_dict = {}\n",
    "    for key in y_dict:\n",
    "        scaler = StandardScaler()\n",
    "        y_scaled = scaler.fit_transform(np.array(y_dict[key]).reshape(-1, 1)).flatten()\n",
    "        y_dict[key] = y_scaled\n",
    "        scaler_dict[key] = scaler\n",
    "    return X, y_dict, scaler_dict\n",
    "\n",
    "X, y_dict, scaler_dict = prepare_dataset(image_data_list)\n",
    "print(f\"Dataset shape: X={X.shape}, y_dict keys={list(y_dict.keys())}\")\n",
    "\n",
    "# Cell 4: VGG16 transfer learning model\n",
    "def build_transfer_model(input_shape=(iMAGE_PIXEL, iMAGE_PIXEL, 3)):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Cell 5: Training function\n",
    "def train_models(X, y_dict):\n",
    "    models = {}\n",
    "    histories = {}\n",
    "    \n",
    "    for param, y_values in y_dict.items():\n",
    "        print(f\"\\nTraining model for {param}\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_values, test_size=0.2, random_state=42)\n",
    "        model = build_transfer_model()\n",
    "        \n",
    "       # callbacks = [\n",
    "       #     EarlyStopping(patience=5, restore_best_weights=True),\n",
    "       #     ModelCheckpoint(f\"best_model_{param}.h5\", save_best_only=True)\n",
    "       # ]\n",
    "        callbacks = [EarlyStopping(patience=5, restore_best_weights=True)]\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                            epochs=20, batch_size=BATCH_SIZE, verbose=1,\n",
    "                            callbacks=callbacks)\n",
    "        models[param] = model\n",
    "        histories[param] = history\n",
    "    return models, histories\n",
    "\n",
    "# Train models\n",
    "models, histories = train_models(X, y_dict)\n",
    "\n",
    "# Cell 6: Plot MAE for each parameter\n",
    "for param, history in histories.items():\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(history.history['mae'], label='Train MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Val MAE', linestyle='--')\n",
    "    plt.title(f'{param} - MAE Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Absolute Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Cell 7: Evaluation\n",
    "def test_model(models, scaler_dict, X_test=None, y_test_dict=None, new_image_path=None):\n",
    "    results = {}\n",
    "    \n",
    "    if X_test is not None and y_test_dict is not None:\n",
    "        print(f\"\\nEvaluating on test data (samples: {X_test.shape[0]})\")\n",
    "        for param, model in models.items():\n",
    "            test_loss, test_mae = model.evaluate(X_test, y_test_dict[param], verbose=0)\n",
    "            y_pred_scaled = model.predict(X_test, verbose=0).flatten()\n",
    "            y_true_scaled = y_test_dict[param]\n",
    "            r2 = r2_score(y_true_scaled, y_pred_scaled)\n",
    "\n",
    "            # Inverse scale for readability\n",
    "            y_pred = scaler_dict[param].inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "            y_true = scaler_dict[param].inverse_transform(y_true_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "            print(f\"{param} - MSE: {test_loss:.4f}, MAE: {test_mae:.4f}, R²: {r2:.4f}\")\n",
    "            results[param] = {\n",
    "                'MSE': test_loss, 'MAE': test_mae, 'R²': r2,\n",
    "                'y_true': y_true, 'y_pred': y_pred\n",
    "            }\n",
    "    \n",
    "    elif new_image_path is not None:\n",
    "        print(\"\\nPredicting for a new image:\")\n",
    "        img_resized = load_and_preprocess_image(new_image_path)\n",
    "        img_processed = preprocess_input(img_resized)\n",
    "        img_processed = np.expand_dims(img_processed, axis=0)\n",
    "        \n",
    "        for param, model in models.items():\n",
    "            pred_scaled = model.predict(img_processed, verbose=0)[0][0]\n",
    "            pred = scaler_dict[param].inverse_transform([[pred_scaled]])[0][0]\n",
    "            results[param] = pred\n",
    "            print(f\"Predicted {param}: {pred:.4f}\")\n",
    "    else:\n",
    "        raise ValueError(\"Provide either test data or new_image_path\")\n",
    "    return results\n",
    "\n",
    "# Cell 8: Evaluate on test data\n",
    "X_train, X_test, y_train_dict, y_test_dict = {}, {}, {}, {}\n",
    "for param, y_values in y_dict.items():\n",
    "    X_train[param], X_test[param], y_train_dict[param], y_test_dict[param] = train_test_split(\n",
    "        X, y_values, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "test_results = test_model(models, scaler_dict, X_test['AQI'], y_test_dict)\n",
    "\n",
    "# Cell 9: Predict new image\n",
    "new_image_path = \"F:/Pheonix/Thesis/Project/Code/AQI Index/.venv/Dev/Data/cleaned_folder/BRI_Un_2023-02-02- 12.00-9.jpg\"\n",
    "pred_results = test_model(models, scaler_dict, new_image_path=new_image_path)\n",
    "\n",
    "# Cell 10: Display prediction\n",
    "img = load_and_preprocess_image(new_image_path)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "plt.suptitle(\"Predictions:\\n\" + \"\\n\".join(f\"{param}: {value:.2f}\" for param, value in pred_results.items()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42354e35-2b2b-4cf7-bfe1-45e8928506c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
